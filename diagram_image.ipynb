{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a17c49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/OllamaGraphRAGPoC/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import torch\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c4cc14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "# Load the BLIP model\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    images = []\n",
    "    for page_index in range(len(doc)):\n",
    "        page = doc[page_index]\n",
    "        for img_index, img in enumerate(page.get_images(full=True)):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image_ext = base_image[\"ext\"]\n",
    "            images.append((page_index + 1, image_bytes, image_ext))  # page number is 1-based\n",
    "    return images\n",
    "\n",
    "def generate_caption(image_bytes):\n",
    "    image = Image.open(BytesIO(image_bytes)).convert('RGB')\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    out = model.generate(**inputs)\n",
    "    caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "    return caption\n",
    "\n",
    "def process_pdf_for_images(pdf_path, output_json=\"image_captions.json\"):\n",
    "    images = extract_images_from_pdf(pdf_path)\n",
    "    results = []\n",
    "\n",
    "    for page_num, image_bytes, image_ext in images:\n",
    "        caption = generate_caption(image_bytes)\n",
    "        result = {\n",
    "            \"type\": \"figure\",\n",
    "            \"page\": page_num,\n",
    "            \"caption\": caption,\n",
    "            \"source_pdf\": os.path.basename(pdf_path)\n",
    "        }\n",
    "        results.append(result)\n",
    "        print(f\"[Page {page_num}] Caption: {caption}\")\n",
    "\n",
    "    with open(output_json, \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f42e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Page 1] Caption: the logo for the software company, which is headquartered by broad\n",
      "[Page 1] Caption: a rainbow colored background\n",
      "[Page 2] Caption: the logo for the software company, which is headquartered by broad\n",
      "[Page 2] Caption: a rainbow colored background\n",
      "[Page 2] Caption: the diagram of the solar energy system\n",
      "[Page 3] Caption: the logo for the software company, which is headquartered by broad\n",
      "[Page 3] Caption: a rainbow colored background\n",
      "[Page 3] Caption: vm and vm - vm diagram\n",
      "[Page 4] Caption: the logo for the software company, which is headquartered by broad\n",
      "[Page 4] Caption: a rainbow colored background\n",
      "[Page 4] Caption: vm - vm - vm - vm - vm - vm vm v\n",
      "[Page 4] Caption: the vkna server and vkna server\n",
      "[Page 5] Caption: the logo for the software company, which is headquartered by broad\n",
      "[Page 5] Caption: a rainbow colored background\n",
      "[Page 5] Caption: the same image of the same image of the same image of the same image\n",
      "[Page 6] Caption: the logo for the software company, which is headquartered by broad\n",
      "[Page 6] Caption: a rainbow colored background\n",
      "[\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 1,\n",
      "    \"caption\": \"the logo for the software company, which is headquartered by broad\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 1,\n",
      "    \"caption\": \"a rainbow colored background\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 2,\n",
      "    \"caption\": \"the logo for the software company, which is headquartered by broad\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 2,\n",
      "    \"caption\": \"a rainbow colored background\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 2,\n",
      "    \"caption\": \"the diagram of the solar energy system\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 3,\n",
      "    \"caption\": \"the logo for the software company, which is headquartered by broad\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 3,\n",
      "    \"caption\": \"a rainbow colored background\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 3,\n",
      "    \"caption\": \"vm and vm - vm diagram\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 4,\n",
      "    \"caption\": \"the logo for the software company, which is headquartered by broad\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 4,\n",
      "    \"caption\": \"a rainbow colored background\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 4,\n",
      "    \"caption\": \"vm - vm - vm - vm - vm - vm vm v\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 4,\n",
      "    \"caption\": \"the vkna server and vkna server\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 5,\n",
      "    \"caption\": \"the logo for the software company, which is headquartered by broad\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 5,\n",
      "    \"caption\": \"a rainbow colored background\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 5,\n",
      "    \"caption\": \"the same image of the same image of the same image of the same image\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 6,\n",
      "    \"caption\": \"the logo for the software company, which is headquartered by broad\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 6,\n",
      "    \"caption\": \"a rainbow colored background\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "results = process_pdf_for_images(\"/workspace/OllamaGraphRAGPoC/input-dir/split_5.pdf\")\n",
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cb4b0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Page 1] Caption: a diagram of the different types of wind turbines\n",
      "[Page 1] Caption: wind turbines are used to generate electricity from the wind\n",
      "[Page 2] Caption: a diagram of wind turbines\n",
      "[Page 2] Caption: a wind turbine on a blue sky\n",
      "[Page 2] Caption: a wind turbine on a pole\n",
      "[Page 2] Caption: a wind turbine\n",
      "[\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 1,\n",
      "    \"caption\": \"a diagram of the different types of wind turbines\",\n",
      "    \"source_pdf\": \"test_1.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 1,\n",
      "    \"caption\": \"wind turbines are used to generate electricity from the wind\",\n",
      "    \"source_pdf\": \"test_1.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 2,\n",
      "    \"caption\": \"a diagram of wind turbines\",\n",
      "    \"source_pdf\": \"test_1.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 2,\n",
      "    \"caption\": \"a wind turbine on a blue sky\",\n",
      "    \"source_pdf\": \"test_1.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 2,\n",
      "    \"caption\": \"a wind turbine on a pole\",\n",
      "    \"source_pdf\": \"test_1.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 2,\n",
      "    \"caption\": \"a wind turbine\",\n",
      "    \"source_pdf\": \"test_1.pdf\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "results = process_pdf_for_images(\"/workspace/OllamaGraphRAGPoC/input-dir/test_1.pdf\")\n",
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42316c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85018017",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00, 17.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load LLaVA model (7B version; use 13B if enough VRAM)\n",
    "model_id = \"llava-hf/llava-1.5-7b-hf\"\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\"\n",
    ")\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    images = []\n",
    "    for page_index in range(len(doc)):\n",
    "        page = doc[page_index]\n",
    "        for img_index, img in enumerate(page.get_images(full=True)):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image_ext = base_image[\"ext\"]\n",
    "            images.append((page_index + 1, image_bytes, image_ext))\n",
    "    return images\n",
    "\n",
    "def generate_caption_llava(image_bytes, question=\"What does this diagram show?\"):\n",
    "    image = Image.open(BytesIO(image_bytes)).convert(\"RGB\")\n",
    "    prompt = f\"USER: <image>\\n{question}\\nASSISTANT:\"\n",
    "    inputs = processor(prompt, image, return_tensors=\"pt\").to(model.device)\n",
    "    output = model.generate(**inputs, max_new_tokens=150)\n",
    "    caption = processor.decode(output[0], skip_special_tokens=True)\n",
    "    return caption\n",
    "\n",
    "def process_pdf_with_llava(pdf_path, output_json=\"llava_image_captions.json\"):\n",
    "    images = extract_images_from_pdf(pdf_path)\n",
    "    results = []\n",
    "\n",
    "    for page_num, image_bytes, image_ext in images:\n",
    "        caption = generate_caption_llava(image_bytes)\n",
    "        result = {\n",
    "            \"type\": \"figure\",\n",
    "            \"page\": page_num,\n",
    "            \"caption\": caption,\n",
    "            \"source_pdf\": os.path.basename(pdf_path)\n",
    "        }\n",
    "        results.append(result)\n",
    "        print(f\"[Page {page_num}] Caption: {caption}\")\n",
    "\n",
    "    with open(output_json, \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43803dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You may have used the wrong order for inputs. `images` should be passed before `text`. The `images` and `text` inputs will be swapped. This behavior will be deprecated in transformers v4.47.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Page 1] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram shows a computer network with multiple devices connected to it. There are two main devices in the image: a laptop and a desktop computer. The laptop is positioned on the left side of the image, while the desktop computer is located on the right side. \n",
      "\n",
      "In addition to the laptop and desktop computer, there are three other devices in the network: two cell phones and a mouse. The cell phones are placed near the laptop, while the mouse is situated closer to the desktop computer. This diagram illustrates a typical modern workspace with various devices connected to the network.\n",
      "[Page 1] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram shows a blue sky with no clouds, providing a clear and bright atmosphere. The sky is a deep shade of blue, indicating a sunny day with good weather conditions.\n",
      "[Page 2] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram shows a computer network with multiple devices connected to it. There are two main devices in the image: a laptop and a desktop computer. The laptop is positioned on the left side of the image, while the desktop computer is located on the right side. \n",
      "\n",
      "In addition to the laptop and desktop computer, there are three other devices in the network: two cell phones and a mouse. The cell phones are placed near the laptop, while the mouse is situated closer to the desktop computer. This diagram illustrates a typical modern workspace with various devices connected to the network.\n",
      "[Page 2] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram shows a blue sky with no clouds, providing a clear and bright atmosphere. The sky is a deep shade of blue, indicating a sunny day with good weather conditions.\n",
      "[Page 2] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram is a flowchart that illustrates the different levels of service provided by HANA (SAP HANA). It shows the various stages of service, from the basic level to the advanced level. The flowchart is color-coded, with different colors representing different stages of service. The diagram also includes a clock, which might indicate the time-sensitive nature of some services. Overall, the flowchart provides a clear visual representation of the service levels offered by HANA.\n",
      "[Page 3] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram shows a computer network with multiple devices connected to it. There are two main devices in the image: a laptop and a desktop computer. The laptop is positioned on the left side of the image, while the desktop computer is located on the right side. \n",
      "\n",
      "In addition to the laptop and desktop computer, there are three other devices in the network: two cell phones and a mouse. The cell phones are placed near the laptop, while the mouse is situated closer to the desktop computer. This diagram illustrates a typical modern workspace with various devices connected to the network.\n",
      "[Page 3] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram shows a blue sky with no clouds, providing a clear and bright atmosphere. The sky is a deep shade of blue, indicating a sunny day with good weather conditions.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_pdf_with_llava\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/workspace/OllamaGraphRAGPoC/input-dir/split_5.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
       "File \u001b[0;32m/workspace/OllamaGraphRAGPoC/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = process_pdf_with_llava(\"/workspace/OllamaGraphRAGPoC/input-dir/split_5.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76246160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Page 1] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram shows a representation of a power plant, specifically focusing on the process of generating electricity. The image consists of three main components: a transformer, a power line, and a transformer. The transformer is connected to the power line, which is connected to the transformer. The image also includes a box labeled \"transformers\" and a box labeled \"power lines.\" The arrangement of these components illustrates the flow of electricity from the power plant to the consumer.\n",
      "[Page 1] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram shows a side-by-side comparison of two different views of wind turbines. In one view, the wind turbines are shown in a close-up perspective, while in the other view, they are shown from a distance, giving a broader perspective of the landscape. The two images are placed next to each other, allowing viewers to compare the size and scale of the wind turbines in both perspectives.\n",
      "[Page 2] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram shows a comparison between different types of wind turbines. There are four wind turbines in the image, each with varying heights and designs. The turbines are labeled with their respective heights, ranging from 30 meters to 60 meters. The diagram provides a visual representation of the differences in size and design among these wind turbines, allowing viewers to better understand the various options available for harnessing wind energy.\n",
      "[Page 2] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram shows a large wind turbine with a long, thin blade, mounted on a blue background. The wind turbine is designed to harness the power of the wind and convert it into electricity. The image provides a clear view of the wind turbine's structure and its components, highlighting the importance of wind energy in sustainable energy production.\n",
      "[Page 2] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram shows a wind turbine, which is a device that converts wind energy into electrical energy. The wind turbine is mounted on a tall pole and has a large propeller-like structure at the top. The propeller is designed to capture the wind and generate power, which is then transmitted to the electrical grid or used for other purposes. The image illustrates the concept of harnessing wind energy to produce clean and renewable energy.\n",
      "[Page 2] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram shows a wind turbine, which is a device that converts wind energy into electrical energy. The wind turbine consists of a large white blade, which is the main part of the device that catches the wind. The blade is connected to a vertical axis, and the wind's force is used to turn the blade, which in turn drives a generator to produce electricity. The image captures the wind turbine in action, with the blade spinning in the blue sky.\n"
     ]
    }
   ],
   "source": [
    "results = process_pdf_with_llava(\"/workspace/OllamaGraphRAGPoC/input-dir/test_1.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "271ddd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy InRelease [270 kB]                \n",
      "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1581 B]\n",
      "0% [2 InRelease 19.3 kB/270 kB 7%] [1 InRelease 38.8 kB/129 kB 30%] [Waiting fo"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1683 kB]\n",
      "Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]        \n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
      "Get:8 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [47.7 kB]\n",
      "Get:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1245 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 Packages [1792 kB]\n",
      "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2944 kB]\n",
      "Get:12 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4387 kB]\n",
      "Get:13 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [34.2 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy/restricted amd64 Packages [164 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy/universe amd64 Packages [17.5 MB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 Packages [266 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4540 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1552 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [55.7 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3255 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.2 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
      "Fetched 40.2 MB in 2s (21.7 MB/s)                             \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libcairo2 liblcms2-2 libnspr4 libnss3 libopenjp2-7 libpixman-1-0\n",
      "  libpoppler118 libxcb-render0 libxrender1 poppler-data\n",
      "Suggested packages:\n",
      "  liblcms2-utils ghostscript fonts-japanese-mincho | fonts-ipafont-mincho\n",
      "  fonts-japanese-gothic | fonts-ipafont-gothic fonts-arphic-ukai\n",
      "  fonts-arphic-uming fonts-nanum\n",
      "The following NEW packages will be installed:\n",
      "  libcairo2 liblcms2-2 libnspr4 libnss3 libopenjp2-7 libpixman-1-0\n",
      "  libpoppler118 libxcb-render0 libxrender1 poppler-data poppler-utils\n",
      "0 upgraded, 11 newly installed, 0 to remove and 143 not upgraded.\n",
      "Need to get 6139 kB of archives.\n",
      "After this operation, 25.2 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 poppler-data all 0.4.11-1 [2171 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpixman-1-0 amd64 0.40.0-1ubuntu0.22.04.1 [264 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-render0 amd64 1.14-3ubuntu3 [16.4 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxrender1 amd64 1:0.9.10-1build4 [19.7 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libcairo2 amd64 1.16.0-5ubuntu2 [628 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblcms2-2 amd64 2.12~rc1-2build2 [159 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libnspr4 amd64 2:4.35-0ubuntu0.22.04.1 [119 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libnss3 amd64 2:3.98-0ubuntu0.22.04.2 [1347 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libopenjp2-7 amd64 2.4.0-6ubuntu0.3 [158 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler118 amd64 22.02.0-2ubuntu0.8 [1072 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.8 [186 kB]\n",
      "Fetched 6139 kB in 0s (16.0 MB/s)        \n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package poppler-data.\n",
      "(Reading database ... 20729 files and directories currently installed.)\n",
      "Preparing to unpack .../00-poppler-data_0.4.11-1_all.deb ...\n",
      "Unpacking poppler-data (0.4.11-1) ...\n",
      "Selecting previously unselected package libpixman-1-0:amd64.\n",
      "Preparing to unpack .../01-libpixman-1-0_0.40.0-1ubuntu0.22.04.1_amd64.deb ...\n",
      "Unpacking libpixman-1-0:amd64 (0.40.0-1ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package libxcb-render0:amd64.\n",
      "Preparing to unpack .../02-libxcb-render0_1.14-3ubuntu3_amd64.deb ...\n",
      "Unpacking libxcb-render0:amd64 (1.14-3ubuntu3) ...\n",
      "Selecting previously unselected package libxrender1:amd64.\n",
      "Preparing to unpack .../03-libxrender1_1%3a0.9.10-1build4_amd64.deb ...\n",
      "Unpacking libxrender1:amd64 (1:0.9.10-1build4) ...\n",
      "Selecting previously unselected package libcairo2:amd64.\n",
      "Preparing to unpack .../04-libcairo2_1.16.0-5ubuntu2_amd64.deb ...\n",
      "Unpacking libcairo2:amd64 (1.16.0-5ubuntu2) ...\n",
      "Selecting previously unselected package liblcms2-2:amd64.\n",
      "Preparing to unpack .../05-liblcms2-2_2.12~rc1-2build2_amd64.deb ...\n",
      "Unpacking liblcms2-2:amd64 (2.12~rc1-2build2) ...\n",
      "Selecting previously unselected package libnspr4:amd64.\n",
      "Preparing to unpack .../06-libnspr4_2%3a4.35-0ubuntu0.22.04.1_amd64.deb ...\n",
      "Unpacking libnspr4:amd64 (2:4.35-0ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package libnss3:amd64.\n",
      "Preparing to unpack .../07-libnss3_2%3a3.98-0ubuntu0.22.04.2_amd64.deb ...\n",
      "Unpacking libnss3:amd64 (2:3.98-0ubuntu0.22.04.2) ...\n",
      "Selecting previously unselected package libopenjp2-7:amd64.\n",
      "Preparing to unpack .../08-libopenjp2-7_2.4.0-6ubuntu0.3_amd64.deb ...\n",
      "Unpacking libopenjp2-7:amd64 (2.4.0-6ubuntu0.3) ...\n",
      "Selecting previously unselected package libpoppler118:amd64.\n",
      "Preparing to unpack .../09-libpoppler118_22.02.0-2ubuntu0.8_amd64.deb ...\n",
      "Unpacking libpoppler118:amd64 (22.02.0-2ubuntu0.8) ...\n",
      "Selecting previously unselected package poppler-utils.\n",
      "Preparing to unpack .../10-poppler-utils_22.02.0-2ubuntu0.8_amd64.deb ...\n",
      "Unpacking poppler-utils (22.02.0-2ubuntu0.8) ...\n",
      "Setting up liblcms2-2:amd64 (2.12~rc1-2build2) ...\n",
      "Setting up libpixman-1-0:amd64 (0.40.0-1ubuntu0.22.04.1) ...\n",
      "Setting up libxrender1:amd64 (1:0.9.10-1build4) ...\n",
      "Setting up libxcb-render0:amd64 (1.14-3ubuntu3) ...\n",
      "Setting up libcairo2:amd64 (1.16.0-5ubuntu2) ...\n",
      "Setting up poppler-data (0.4.11-1) ...\n",
      "Setting up libnspr4:amd64 (2:4.35-0ubuntu0.22.04.1) ...\n",
      "Setting up libopenjp2-7:amd64 (2.4.0-6ubuntu0.3) ...\n",
      "Setting up libnss3:amd64 (2:3.98-0ubuntu0.22.04.2) ...\n",
      "Setting up libpoppler118:amd64 (22.02.0-2ubuntu0.8) ...\n",
      "Setting up poppler-utils (22.02.0-2ubuntu0.8) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n"
     ]
    }
   ],
   "source": [
    "# Install Poppler (required for pdf2image)\n",
    "!apt-get update && apt-get install -y poppler-utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f82d0602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Page 1 ---\n",
      "Answer: What does the diagram show? diodes are used to generate the diodes. The diodes are connected to the AC and AC\n"
     ]
    }
   ],
   "source": [
    "from transformers import Pix2StructProcessor, Pix2StructForConditionalGeneration\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Load model and processor\n",
    "processor = Pix2StructProcessor.from_pretrained(\"google/pix2struct-base\", token=token)\n",
    "model = Pix2StructForConditionalGeneration.from_pretrained(\"google/pix2struct-base\", token=token)\n",
    "\n",
    "# Load your PDF and convert pages to images\n",
    "pdf_path = \"/workspace/OllamaGraphRAGPoC/input-dir/diagram.pdf\"\n",
    "images = convert_from_path(pdf_path, dpi=200)\n",
    "\n",
    "# You can modify the question per your needs\n",
    "question = \"What does the diagram show?\"\n",
    "\n",
    "# Loop through pages\n",
    "for idx, image in enumerate(images):\n",
    "    print(f\"\\n--- Page {idx + 1} ---\")\n",
    "    # Convert image to RGB (in case it's grayscale)\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "    # Preprocess and generate answer\n",
    "    inputs = processor(images=image, text=question, return_tensors=\"pt\").to(model.device)\n",
    "    predictions = model.generate(**inputs)\n",
    "\n",
    "    # Decode and print\n",
    "    caption = processor.decode(predictions[0], skip_special_tokens=True)\n",
    "    print(\"Answer:\", caption)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
