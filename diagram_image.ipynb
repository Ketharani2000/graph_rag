{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a17c49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/OllamaGraphRAGPoC/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import torch\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c4cc14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "# Load the BLIP model\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    images = []\n",
    "    for page_index in range(len(doc)):\n",
    "        page = doc[page_index]\n",
    "        for img_index, img in enumerate(page.get_images(full=True)):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image_ext = base_image[\"ext\"]\n",
    "            images.append((page_index + 1, image_bytes, image_ext))  # page number is 1-based\n",
    "    return images\n",
    "\n",
    "def generate_caption(image_bytes):\n",
    "    image = Image.open(BytesIO(image_bytes)).convert('RGB')\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    out = model.generate(**inputs)\n",
    "    caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "    return caption\n",
    "\n",
    "def process_pdf_for_images(pdf_path, output_json=\"image_captions.json\"):\n",
    "    images = extract_images_from_pdf(pdf_path)\n",
    "    results = []\n",
    "\n",
    "    for page_num, image_bytes, image_ext in images:\n",
    "        caption = generate_caption(image_bytes)\n",
    "        result = {\n",
    "            \"type\": \"figure\",\n",
    "            \"page\": page_num,\n",
    "            \"caption\": caption,\n",
    "            \"source_pdf\": os.path.basename(pdf_path)\n",
    "        }\n",
    "        results.append(result)\n",
    "        print(f\"[Page {page_num}] Caption: {caption}\")\n",
    "\n",
    "    with open(output_json, \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f42e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Page 1] Caption: the logo for the software company, which is headquartered by broad\n",
      "[Page 1] Caption: a rainbow colored background\n",
      "[Page 2] Caption: the logo for the software company, which is headquartered by broad\n",
      "[Page 2] Caption: a rainbow colored background\n",
      "[Page 2] Caption: the diagram of the solar energy system\n",
      "[Page 3] Caption: the logo for the software company, which is headquartered by broad\n",
      "[Page 3] Caption: a rainbow colored background\n",
      "[Page 3] Caption: vm and vm - vm diagram\n",
      "[Page 4] Caption: the logo for the software company, which is headquartered by broad\n",
      "[Page 4] Caption: a rainbow colored background\n",
      "[Page 4] Caption: vm - vm - vm - vm - vm - vm vm v\n",
      "[Page 4] Caption: the vkna server and vkna server\n",
      "[Page 5] Caption: the logo for the software company, which is headquartered by broad\n",
      "[Page 5] Caption: a rainbow colored background\n",
      "[Page 5] Caption: the same image of the same image of the same image of the same image\n",
      "[Page 6] Caption: the logo for the software company, which is headquartered by broad\n",
      "[Page 6] Caption: a rainbow colored background\n",
      "[\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 1,\n",
      "    \"caption\": \"the logo for the software company, which is headquartered by broad\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 1,\n",
      "    \"caption\": \"a rainbow colored background\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 2,\n",
      "    \"caption\": \"the logo for the software company, which is headquartered by broad\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 2,\n",
      "    \"caption\": \"a rainbow colored background\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 2,\n",
      "    \"caption\": \"the diagram of the solar energy system\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 3,\n",
      "    \"caption\": \"the logo for the software company, which is headquartered by broad\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 3,\n",
      "    \"caption\": \"a rainbow colored background\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 3,\n",
      "    \"caption\": \"vm and vm - vm diagram\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 4,\n",
      "    \"caption\": \"the logo for the software company, which is headquartered by broad\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 4,\n",
      "    \"caption\": \"a rainbow colored background\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 4,\n",
      "    \"caption\": \"vm - vm - vm - vm - vm - vm vm v\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 4,\n",
      "    \"caption\": \"the vkna server and vkna server\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 5,\n",
      "    \"caption\": \"the logo for the software company, which is headquartered by broad\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 5,\n",
      "    \"caption\": \"a rainbow colored background\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 5,\n",
      "    \"caption\": \"the same image of the same image of the same image of the same image\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 6,\n",
      "    \"caption\": \"the logo for the software company, which is headquartered by broad\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 6,\n",
      "    \"caption\": \"a rainbow colored background\",\n",
      "    \"source_pdf\": \"split_5.pdf\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "results = process_pdf_for_images(\"/workspace/OllamaGraphRAGPoC/input-dir/split_5.pdf\")\n",
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cb4b0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Page 1] Caption: a diagram of the different types of wind turbines\n",
      "[Page 1] Caption: wind turbines are used to generate electricity from the wind\n",
      "[Page 2] Caption: a diagram of wind turbines\n",
      "[Page 2] Caption: a wind turbine on a blue sky\n",
      "[Page 2] Caption: a wind turbine on a pole\n",
      "[Page 2] Caption: a wind turbine\n",
      "[\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 1,\n",
      "    \"caption\": \"a diagram of the different types of wind turbines\",\n",
      "    \"source_pdf\": \"test_1.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 1,\n",
      "    \"caption\": \"wind turbines are used to generate electricity from the wind\",\n",
      "    \"source_pdf\": \"test_1.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 2,\n",
      "    \"caption\": \"a diagram of wind turbines\",\n",
      "    \"source_pdf\": \"test_1.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 2,\n",
      "    \"caption\": \"a wind turbine on a blue sky\",\n",
      "    \"source_pdf\": \"test_1.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 2,\n",
      "    \"caption\": \"a wind turbine on a pole\",\n",
      "    \"source_pdf\": \"test_1.pdf\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"figure\",\n",
      "    \"page\": 2,\n",
      "    \"caption\": \"a wind turbine\",\n",
      "    \"source_pdf\": \"test_1.pdf\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "results = process_pdf_for_images(\"/workspace/OllamaGraphRAGPoC/input-dir/test_1.pdf\")\n",
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42316c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85018017",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00, 17.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load LLaVA model (7B version; use 13B if enough VRAM)\n",
    "model_id = \"llava-hf/llava-1.5-7b-hf\"\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\"\n",
    ")\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    images = []\n",
    "    for page_index in range(len(doc)):\n",
    "        page = doc[page_index]\n",
    "        for img_index, img in enumerate(page.get_images(full=True)):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image_ext = base_image[\"ext\"]\n",
    "            images.append((page_index + 1, image_bytes, image_ext))\n",
    "    return images\n",
    "\n",
    "def generate_caption_llava(image_bytes, question=\"What does this diagram show?\"):\n",
    "    image = Image.open(BytesIO(image_bytes)).convert(\"RGB\")\n",
    "    prompt = f\"USER: <image>\\n{question}\\nASSISTANT:\"\n",
    "    inputs = processor(prompt, image, return_tensors=\"pt\").to(model.device)\n",
    "    output = model.generate(**inputs, max_new_tokens=150)\n",
    "    caption = processor.decode(output[0], skip_special_tokens=True)\n",
    "    return caption\n",
    "\n",
    "def process_pdf_with_llava(pdf_path, output_json=\"llava_image_captions.json\"):\n",
    "    images = extract_images_from_pdf(pdf_path)\n",
    "    results = []\n",
    "\n",
    "    for page_num, image_bytes, image_ext in images:\n",
    "        caption = generate_caption_llava(image_bytes)\n",
    "        result = {\n",
    "            \"type\": \"figure\",\n",
    "            \"page\": page_num,\n",
    "            \"caption\": caption,\n",
    "            \"source_pdf\": os.path.basename(pdf_path)\n",
    "        }\n",
    "        results.append(result)\n",
    "        print(f\"[Page {page_num}] Caption: {caption}\")\n",
    "\n",
    "    with open(output_json, \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43803dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You may have used the wrong order for inputs. `images` should be passed before `text`. The `images` and `text` inputs will be swapped. This behavior will be deprecated in transformers v4.47.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Page 1] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram shows a computer network with multiple devices connected to it. There are two main devices in the image: a laptop and a desktop computer. The laptop is positioned on the left side of the image, while the desktop computer is located on the right side. \n",
      "\n",
      "In addition to the laptop and desktop computer, there are three other devices in the network: two cell phones and a mouse. The cell phones are placed near the laptop, while the mouse is situated closer to the desktop computer. This diagram illustrates a typical modern workspace with various devices connected to the network.\n",
      "[Page 1] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram shows a blue sky with no clouds, providing a clear and bright atmosphere. The sky is a deep shade of blue, indicating a sunny day with good weather conditions.\n",
      "[Page 2] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram shows a computer network with multiple devices connected to it. There are two main devices in the image: a laptop and a desktop computer. The laptop is positioned on the left side of the image, while the desktop computer is located on the right side. \n",
      "\n",
      "In addition to the laptop and desktop computer, there are three other devices in the network: two cell phones and a mouse. The cell phones are placed near the laptop, while the mouse is situated closer to the desktop computer. This diagram illustrates a typical modern workspace with various devices connected to the network.\n",
      "[Page 2] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram shows a blue sky with no clouds, providing a clear and bright atmosphere. The sky is a deep shade of blue, indicating a sunny day with good weather conditions.\n",
      "[Page 2] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram is a flowchart that illustrates the different levels of service provided by HANA (SAP HANA). It shows the various stages of service, from the basic level to the advanced level. The flowchart is color-coded, with different colors representing different stages of service. The diagram also includes a clock, which might indicate the time-sensitive nature of some services. Overall, the flowchart provides a clear visual representation of the service levels offered by HANA.\n",
      "[Page 3] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram shows a computer network with multiple devices connected to it. There are two main devices in the image: a laptop and a desktop computer. The laptop is positioned on the left side of the image, while the desktop computer is located on the right side. \n",
      "\n",
      "In addition to the laptop and desktop computer, there are three other devices in the network: two cell phones and a mouse. The cell phones are placed near the laptop, while the mouse is situated closer to the desktop computer. This diagram illustrates a typical modern workspace with various devices connected to the network.\n",
      "[Page 3] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram shows a blue sky with no clouds, providing a clear and bright atmosphere. The sky is a deep shade of blue, indicating a sunny day with good weather conditions.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_pdf_with_llava\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/workspace/OllamaGraphRAGPoC/input-dir/split_5.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
       "File \u001b[0;32m/workspace/OllamaGraphRAGPoC/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = process_pdf_with_llava(\"/workspace/OllamaGraphRAGPoC/input-dir/split_5.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76246160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Page 1] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram shows a representation of a power plant, specifically focusing on the process of generating electricity. The image consists of three main components: a transformer, a power line, and a transformer. The transformer is connected to the power line, which is connected to the transformer. The image also includes a box labeled \"transformers\" and a box labeled \"power lines.\" The arrangement of these components illustrates the flow of electricity from the power plant to the consumer.\n",
      "[Page 1] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram shows a side-by-side comparison of two different views of wind turbines. In one view, the wind turbines are shown in a close-up perspective, while in the other view, they are shown from a distance, giving a broader perspective of the landscape. The two images are placed next to each other, allowing viewers to compare the size and scale of the wind turbines in both perspectives.\n",
      "[Page 2] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram shows a comparison between different types of wind turbines. There are four wind turbines in the image, each with varying heights and designs. The turbines are labeled with their respective heights, ranging from 30 meters to 60 meters. The diagram provides a visual representation of the differences in size and design among these wind turbines, allowing viewers to better understand the various options available for harnessing wind energy.\n",
      "[Page 2] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram shows a large wind turbine with a long, thin blade, mounted on a blue background. The wind turbine is designed to harness the power of the wind and convert it into electricity. The image provides a clear view of the wind turbine's structure and its components, highlighting the importance of wind energy in sustainable energy production.\n",
      "[Page 2] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram shows a wind turbine, which is a device that converts wind energy into electrical energy. The wind turbine is mounted on a tall pole and has a large propeller-like structure at the top. The propeller is designed to capture the wind and generate power, which is then transmitted to the electrical grid or used for other purposes. The image illustrates the concept of harnessing wind energy to produce clean and renewable energy.\n",
      "[Page 2] Caption: USER:  \n",
      "What does this diagram show?\n",
      "ASSISTANT: The diagram shows a wind turbine, which is a device that converts wind energy into electrical energy. The wind turbine consists of a large white blade, which is the main part of the device that catches the wind. The blade is connected to a vertical axis, and the wind's force is used to turn the blade, which in turn drives a generator to produce electricity. The image captures the wind turbine in action, with the blade spinning in the blue sky.\n"
     ]
    }
   ],
   "source": [
    "results = process_pdf_with_llava(\"/workspace/OllamaGraphRAGPoC/input-dir/test_1.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "271ddd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy InRelease [270 kB]                \n",
      "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1581 B]\n",
      "0% [2 InRelease 19.3 kB/270 kB 7%] [1 InRelease 38.8 kB/129 kB 30%] [Waiting fo"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
    
     ]
    }
   ],
   "source": [
    "# Install Poppler (required for pdf2image)\n",
    "!apt-get update && apt-get install -y poppler-utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f82d0602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Page 1 ---\n",
      "Answer: What does the diagram show? diodes are used to generate the diodes. The diodes are connected to the AC and AC\n"
     ]
    }
   ],
   "source": [
    "from transformers import Pix2StructProcessor, Pix2StructForConditionalGeneration\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Load model and processor\n",
    "processor = Pix2StructProcessor.from_pretrained(\"google/pix2struct-base\", token=token)\n",
    "model = Pix2StructForConditionalGeneration.from_pretrained(\"google/pix2struct-base\", token=token)\n",
    "\n",
    "# Load your PDF and convert pages to images\n",
    "pdf_path = \"/workspace/OllamaGraphRAGPoC/input-dir/diagram.pdf\"\n",
    "images = convert_from_path(pdf_path, dpi=200)\n",
    "\n",
    "# You can modify the question per your needs\n",
    "question = \"What does the diagram show?\"\n",
    "\n",
    "# Loop through pages\n",
    "for idx, image in enumerate(images):\n",
    "    print(f\"\\n--- Page {idx + 1} ---\")\n",
    "    # Convert image to RGB (in case it's grayscale)\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "    # Preprocess and generate answer\n",
    "    inputs = processor(images=image, text=question, return_tensors=\"pt\").to(model.device)\n",
    "    predictions = model.generate(**inputs)\n",
    "\n",
    "    # Decode and print\n",
    "    caption = processor.decode(predictions[0], skip_special_tokens=True)\n",
    "    print(\"Answer:\", caption)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
